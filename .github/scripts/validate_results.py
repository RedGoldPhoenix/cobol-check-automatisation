#!/usr/bin/env python3
"""
GitHub Integration for Test Results
Posts test results to PR/commit comments and validates thresholds
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
import subprocess

def get_github_context():
    """Get GitHub Actions context"""
    context = {
        'event_name': os.getenv('GITHUB_EVENT_NAME'),
        'actor': os.getenv('GITHUB_ACTOR'),
        'repo': os.getenv('GITHUB_REPOSITORY'),
        'pr_number': os.getenv('PR_NUMBER'),
        'commit_sha': os.getenv('GITHUB_SHA'),
        'branch': os.getenv('GITHUB_REF_NAME'),
    }
    return context

def parse_test_results(results_dir):
    """Parse test results"""
    summary_file = Path(results_dir) / "SUMMARY.txt"
    if not summary_file.exists():
        return None

    with open(summary_file, 'r') as f:
        content = f.read()

    return content

def create_github_comment(programs_data, totals, results_dir):
    """Create markdown comment for GitHub"""

    comment = """# üß™ COBOL Check Test Results

## Summary Metrics
| Metric | Value |
|--------|-------|
| **Total Tests** | {total_tests} |
| **Tests Passed** | {passed} ‚úÖ |
| **Tests Failed** | {failed} |
| **Overall Coverage** | {coverage}% |
| **Quality Score** | {quality}% |

## Results by Program
| Program | Tests | Passed | Coverage | Quality |
|---------|-------|--------|----------|---------|
""".format(
        total_tests=totals['total_tests'],
        passed=totals['total_passed'],
        failed=totals['total_failed'],
        coverage=totals['overall_coverage'],
        quality=totals['overall_quality']
    )

    for program, data in programs_data.items():
        passed_icon = "‚úÖ" if data['passed'] == data['total_tests'] else "‚ö†Ô∏è"
        comment += f"| {program} | {data['total_tests']} | {data['passed']} {passed_icon} | {data['coverage']}% | {data['quality_score']}% |\n"

    comment += f"""
## Test Details
- **Full Report**: [View HTML Report](./test_report.html)
- **Archived Results**: ./test-results/archive/{datetime.now().strftime('%Y%m%d_%H%M%S')}/

---
*Generated by COBOL Check Automation*
"""

    return comment

def post_github_comment(comment, context):
    """Post comment to GitHub PR or commit"""
    if not context['pr_number']:
        print("‚ÑπÔ∏è  No PR number found, skipping GitHub comment")
        return True

    pr_number = context['pr_number']

    # Use GitHub CLI if available
    try:
        cmd = [
            'gh', 'pr', 'comment', pr_number,
            '--body', comment
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode == 0:
            print(f"‚úÖ Comment posted to PR #{pr_number}")
            return True
        else:
            print(f"‚ùå Failed to post comment: {result.stderr}")
            return False

    except FileNotFoundError:
        print("‚ö†Ô∏è  GitHub CLI (gh) not found, skipping comment")
        return False

def validate_coverage_threshold(totals, threshold=80):
    """Validate code coverage against threshold"""
    coverage = totals['overall_coverage']

    print(f"\nüìä Coverage Validation")
    print(f"Threshold: {threshold}%")
    print(f"Actual: {coverage}%")

    if coverage >= threshold:
        print(f"‚úÖ Coverage meets threshold!")
        return True
    else:
        print(f"‚ùå Coverage below threshold by {threshold - coverage}%")
        return False

def validate_quality_threshold(totals, threshold=80):
    """Validate quality score against threshold"""
    quality = totals['overall_quality']

    print(f"\nüìà Quality Validation")
    print(f"Threshold: {threshold}%")
    print(f"Actual: {quality}%")

    if quality >= threshold:
        print(f"‚úÖ Quality meets threshold!")
        return True
    else:
        print(f"‚ùå Quality below threshold by {threshold - quality}%")
        return False

def validate_all_tests_passed(totals):
    """Check if all critical tests passed"""
    if totals['total_failed'] == 0:
        print(f"\n‚úÖ All tests passed!")
        return True
    else:
        print(f"\n‚ö†Ô∏è  {totals['total_failed']} test(s) failed")
        # Note: This might be expected for negative tests
        return True

def check_coverage_trend(results_dir):
    """Check if coverage is trending up or down"""
    metrics_file = Path(results_dir) / "metrics_history.json"

    if not metrics_file.exists():
        print("\n‚ÑπÔ∏è  No historical data available for trend analysis")
        return None

    try:
        with open(metrics_file, 'r') as f:
            history = json.load(f)

        if len(history) < 2:
            print("\n‚ÑπÔ∏è  Not enough historical data for trend analysis")
            return None

        latest = history[-1]['totals']
        previous = history[-2]['totals']

        coverage_change = latest['overall_coverage'] - previous['overall_coverage']
        quality_change = latest['overall_quality'] - previous['overall_quality']

        print(f"\nüìà Trend Analysis")
        print(f"Coverage change: {coverage_change:+d}% (from {previous['overall_coverage']}% to {latest['overall_coverage']}%)")
        print(f"Quality change: {quality_change:+d}% (from {previous['overall_quality']}% to {latest['overall_quality']}%)")

        if coverage_change < -5:
            print("‚ö†Ô∏è  WARNING: Coverage dropped significantly!")
            return False
        elif coverage_change > 0:
            print("‚úÖ Coverage improved!")
            return True
        else:
            print("‚û°Ô∏è  Coverage stable")
            return True

    except Exception as e:
        print(f"‚ùå Error reading metrics history: {e}")
        return None

def generate_badge(coverage, quality):
    """Generate markdown badge code"""
    badges = f"""
### Build Badges
![Coverage](https://img.shields.io/badge/Coverage-{coverage}%-brightgreen)
![Quality](https://img.shields.io/badge/Quality-{quality}%-blue)
"""
    return badges

def main():
    if len(sys.argv) < 2:
        results_dir = "../test-results"
    else:
        results_dir = sys.argv[1]

    results_dir = Path(results_dir)

    if not results_dir.exists():
        print(f"‚ùå Results directory not found: {results_dir}")
        return 1

    # Parse results
    import re

    summary_file = results_dir / "SUMMARY.txt"
    if not summary_file.exists():
        print("‚ùå Summary file not found")
        return 1

    with open(summary_file, 'r') as f:
        summary = f.read()

    # Extract metrics
    def extract_metric(text, pattern):
        match = re.search(pattern + r':\s*(\d+)', text)
        return int(match.group(1)) if match else 0

    totals = {
        'total_tests': extract_metric(summary, 'Total Test Cases Executed'),
        'total_passed': extract_metric(summary, 'Total Tests Passed'),
        'total_failed': extract_metric(summary, 'Total Tests Failed'),
        'overall_coverage': extract_metric(summary, 'Overall Code Coverage'),
        'overall_quality': extract_metric(summary, 'Overall Test Quality'),
    }

    print("üîç Validating test results...\n")

    # Validate thresholds (configurable via env vars)
    coverage_threshold = int(os.getenv('COVERAGE_THRESHOLD', 75))
    quality_threshold = int(os.getenv('QUALITY_THRESHOLD', 70))

    coverage_ok = validate_coverage_threshold(totals, coverage_threshold)
    quality_ok = validate_quality_threshold(totals, quality_threshold)
    tests_ok = validate_all_tests_passed(totals)
    trend_ok = check_coverage_trend(results_dir)

    # Post to GitHub if available
    context = get_github_context()
    if os.getenv('GITHUB_TOKEN'):
        # Parse programs data for comment
        programs_data = {}
        for program in ["NUMBERS", "EMPPAY", "DEPTPAY"]:
            results_file = results_dir / f"{program}_results.txt"
            if results_file.exists():
                with open(results_file, 'r') as f:
                    content = f.read()
                    programs_data[program] = {
                        'total_tests': extract_metric(content, 'Total Test Cases'),
                        'passed': extract_metric(content, 'Tests Passed'),
                        'coverage': extract_metric(content, 'Code Coverage'),
                        'quality_score': extract_metric(content, 'Test Quality Score'),
                    }

        comment = create_github_comment(programs_data, totals, results_dir)
        post_github_comment(comment, context)

    # Summary
    print("\n" + "="*50)
    print("VALIDATION SUMMARY")
    print("="*50)
    print(f"Coverage Check: {'‚úÖ PASS' if coverage_ok else '‚ùå FAIL'}")
    print(f"Quality Check: {'‚úÖ PASS' if quality_ok else '‚ùå FAIL'}")
    print(f"Tests Check: {'‚úÖ PASS' if tests_ok else '‚ùå FAIL'}")
    print("="*50)

    # Determine exit code
    return 0 if (coverage_ok and quality_ok and tests_ok) else 1

if __name__ == "__main__":
    sys.exit(main())
